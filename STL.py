import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import STL
from statsmodels.stats.diagnostic import acorr_ljungbox
from scipy import stats
import numpy as np
import os
import warnings
import re

warnings.filterwarnings("ignore")

# ========== é…ç½®å‚æ•° ==========
START_DATE = "2024-08-01"
DATA_DIR = "./data/BTC_factors"

# é¢‘ç‡åˆ°å‘¨æœŸçš„æ˜ å°„ï¼ˆæ—¥å‘¨æœŸï¼‰
FREQ_TO_PERIOD = {"10m": 144, "1h": 24, "24h": 7}  # 24 * 6  # 24  # 7 days

# å›¾åƒå’Œç»“æœæŒ‰ period åˆ†å¼€å­˜å‚¨
IMAGE_DIR = "./data/image_multi_freq"
os.makedirs(IMAGE_DIR, exist_ok=True)


# ========== å®‰å…¨å‰å‘å¡«å……ç¼ºå¤±å€¼ï¼ˆä¸æ³„éœ²æœªæ¥ï¼‰==========
def forward_fill_with_limit(series, max_gap=5):
    """
    ç”¨å‰å‘å¡«å……å¤„ç†ç¼ºå¤±å€¼ï¼Œä½†é™åˆ¶æœ€å¤§è¿ç»­ç¼ºå¤±é•¿åº¦
    """
    # å…ˆæ ‡è®°è¿ç»­ç¼ºå¤±æ®µ
    is_na = series.isna()
    # è®¡ç®—è¿ç»­ç¼ºå¤±é•¿åº¦
    na_groups = (~is_na).cumsum()
    na_counts = is_na.groupby(na_groups).transform("sum")

    # åªå¡«å……è¿ç»­ç¼ºå¤± <= max_gap çš„æ®µ
    series_filled = series.copy()
    mask = (is_na) & (na_counts <= max_gap)
    series_filled[mask] = series_filled[mask].fillna(method="ffill")

    return series_filled


# ========== STLä¹˜æ³•åˆ†è§£å‡½æ•° ==========
def stl_multiplicative_decomposition(series, period):
    """
    å¯¹æ—¶é—´åºåˆ—è¿›è¡Œä¹˜æ³•STLåˆ†è§£ï¼ˆé€šè¿‡logå˜æ¢å®ç°ï¼‰
    """
    # ç¡®ä¿æ‰€æœ‰å€¼ä¸ºæ­£æ•°ï¼ˆç”¨äºlogå˜æ¢ï¼‰
    min_val = series.min()
    if min_val <= 0:
        # å¦‚æœæœ‰è´Ÿå€¼æˆ–é›¶ï¼Œå¹³ç§»ä½¿å…¶ä¸ºæ­£
        series_shifted = series - min_val + 1e-6
    else:
        series_shifted = series.copy()

    # å¯¹æ•°æ®å–log
    log_series = np.log(series_shifted)

    # è¿›è¡ŒSTLåˆ†è§£
    stl_model = STL(log_series, period=period, robust=True)
    result = stl_model.fit()

    # æŒ‡æ•°å˜æ¢å›åŸå°ºåº¦
    observed = np.exp(result.observed)
    trend = np.exp(result.trend)
    seasonal = np.exp(result.seasonal)
    resid = np.exp(result.resid)

    # é‡æ–°æ„å»ºï¼Œç¡®ä¿ observed = trend * seasonal * resid
    # ï¼ˆç”±äºæ•°å€¼ç²¾åº¦ï¼Œå¯èƒ½ç•¥æœ‰åå·®ï¼Œè¿™é‡Œé‡æ–°è®¡ç®—residï¼‰
    resid_corrected = observed / (trend * seasonal)

    return {
        "observed": observed,
        "trend": trend,
        "seasonal": seasonal,
        "resid": resid_corrected,
        "original_result": result,  # ä¿ç•™åŸå§‹ç»“æœç”¨äºå…¶ä»–åˆ†æ
    }


# ========== ä¸»å‡½æ•°ï¼šå¤„ç†å•ä¸ªæ–‡ä»¶ ==========
def process_single_factor(
    filepath, category, factor_name, original_frequency, use_multiplicative=False
):
    period = FREQ_TO_PERIOD.get(original_frequency)
    if period is None:
        print(f"âš ï¸ Unsupported frequency: {original_frequency} in {factor_name}")
        return None

    try:
        df = pd.read_csv(filepath)
        df["date"] = pd.to_datetime(df["datetime"])
        df = df[df["date"] > pd.to_datetime(START_DATE)]
        df = df.set_index("date").sort_index()

        if factor_name not in df.columns:
            raise ValueError(f"Column '{factor_name}' not found.")
        series = df[factor_name].copy()
        series = pd.to_numeric(series, errors="coerce")

        # === å¤„ç†ç¼ºå¤±å€¼ï¼šå‰å‘å¡«å……ï¼ˆä¸æ³„éœ²æœªæ¥ï¼‰===
        # å…ˆç¡®ä¿æ—¶é—´è¿ç»­ï¼ˆæŒ‰é¢‘ç‡é‡é‡‡æ ·ï¼Œä½†ä¸èšåˆï¼‰
        freq_map = {"10m": "10T", "1h": "1H", "24h": "1D"}
        pandas_freq = freq_map.get(original_frequency)
        if pandas_freq:
            series = series.asfreq(pandas_freq)  # æ’å…¥ç¼ºå¤±æ—¶é—´ç‚¹

        # å‰å‘å¡«å……çŸ­ç¼ºå£ï¼ˆæœ€å¤š5ä¸ªè¿ç»­ç¼ºå¤±ï¼‰
        series = forward_fill_with_limit(series, max_gap=5)
        series = series.dropna()

        if len(series) < 50:
            raise ValueError("Insufficient data after cleaning.")

        # === STL åˆ†è§£ ===
        if use_multiplicative:
            # ä¹˜æ³•åˆ†è§£
            decomposition_result = stl_multiplicative_decomposition(series, period)
            observed = decomposition_result["observed"].dropna()
            trend = decomposition_result["trend"].dropna()
            seasonal = decomposition_result["seasonal"].dropna()
            resid = decomposition_result["resid"].dropna()
        else:
            # åŠ æ³•åˆ†è§£
            stl_model = STL(series, period=period, robust=True)
            result = stl_model.fit()

            # å¯¹é½æˆåˆ†
            observed = result.observed.dropna()
            trend = result.trend.dropna()
            seasonal = result.seasonal.dropna()
            resid = result.resid.dropna()

        common_idx = (
            observed.index.intersection(trend.index)
            .intersection(seasonal.index)
            .intersection(resid.index)
        )
        trend = trend[common_idx]
        seasonal = seasonal[common_idx]
        resid = resid[common_idx]

        if len(resid) < 10:
            raise ValueError("Too few residuals after alignment.")

        # === å¼ºåº¦è®¡ç®— ===
        eps = 1e-12
        if use_multiplicative:
            # å¯¹äºä¹˜æ³•åˆ†è§£ï¼Œä½¿ç”¨logå°ºåº¦çš„æ–¹å·®æ¥è®¡ç®—å¼ºåº¦
            log_trend = np.log(trend)
            log_seasonal = np.log(seasonal)
            log_resid = np.log(resid)

            trend_var = np.var(log_trend)
            seasonal_var = np.var(log_seasonal)
            resid_var = np.var(log_resid)
            trend_strength = trend_var / (trend_var + resid_var + eps)
            seasonal_strength = seasonal_var / (seasonal_var + resid_var + eps)
        else:
            trend_var = np.var(trend)
            seasonal_var = np.var(seasonal)
            resid_var = np.var(resid)
            trend_strength = trend_var / (trend_var + resid_var + eps)
            seasonal_strength = seasonal_var / (seasonal_var + resid_var + eps)

        # === ä¿å­˜å›¾åƒ ===
        decomposition_type = "multiplicative" if use_multiplicative else "additive"
        image_path = os.path.join(
            IMAGE_DIR, f"{factor_name}_{original_frequency}_{decomposition_type}.png"
        )
        fig, axes = plt.subplots(4, 1, figsize=(12, 10))

        if use_multiplicative:
            observed.plot(
                ax=axes[0],
                title=f"{factor_name} ({original_frequency}) - Multiplicative Decomposition",
            )
            trend.plot(ax=axes[1], title="Trend")
            seasonal.plot(ax=axes[2], title=f"Seasonal (Period={period})")
            resid.plot(ax=axes[3], title="Residuals")
        else:
            result.observed.plot(
                ax=axes[0],
                title=f"{factor_name} ({original_frequency}) - Additive Decomposition",
            )
            result.trend.plot(ax=axes[1], title="Trend")
            result.seasonal.plot(ax=axes[2], title=f"Seasonal (Period={period})")
            result.resid.plot(ax=axes[3], title="Residuals")

        plt.tight_layout()
        plt.savefig(image_path, dpi=150, bbox_inches="tight")
        plt.close(fig)

        # === æ®‹å·®æ£€éªŒ ===
        mean_resid = resid.mean()
        std_resid = resid.std()
        skew_resid = stats.skew(resid)
        kurtosis_resid = stats.kurtosis(resid)

        lb_test = acorr_ljungbox(resid, lags=min(20, len(resid) // 2), return_df=True)
        lb_pvalue = lb_test["lb_pvalue"].iloc[-1]
        passed_white_noise = lb_pvalue > 0.05

        _, normal_pvalue = stats.normaltest(resid)
        passed_normality = normal_pvalue > 0.05

        return {
            "factor_name": factor_name,
            "original_frequency": original_frequency,
            "category": category,
            "period_used": period,
            "decomposition_type": decomposition_type,
            "trend_strength": trend_strength,
            "seasonal_strength": seasonal_strength,
            "mean_resid": mean_resid,
            "std_resid": std_resid,
            "skew_resid": skew_resid,
            "kurtosis_resid": kurtosis_resid,
            "lb_pvalue": lb_pvalue,
            "normal_pvalue": normal_pvalue,
            "passed_white_noise": passed_white_noise,
            "passed_normality": passed_normality,
            "final_length": len(series),
            "image_path": image_path,
        }

    except Exception as e:
        print(f"âŒ Error processing {filepath}: {e}")
        return None


# ========== æ‰¹é‡å¤„ç† ==========
def batch_process_factors(use_multiplicative=False):
    results = []

    for category in os.listdir(DATA_DIR):
        category_path = os.path.join(DATA_DIR, category)
        if not os.path.isdir(category_path):
            continue

        print(f"\nğŸ“‚ Processing category: {category}")

        for filename in os.listdir(category_path):
            if not filename.endswith(".csv"):
                continue

            match = re.match(r"BTC_(\d+[mh])_(.+)\.csv", filename)
            if not match:
                print(f"âš ï¸ Skipping invalid filename: {filename}")
                continue

            freq = match.group(1)
            factor_name = match.group(2)

            if freq not in ["10m", "1h", "24h"]:
                continue

            filepath = os.path.join(category_path, filename)
            print(
                f"âœ… Processing: {factor_name} (freq: {freq}) - {['Additive', 'Multiplicative'][use_multiplicative]} decomposition"
            )

            result = process_single_factor(
                filepath,
                category,
                factor_name,
                freq,
                use_multiplicative=use_multiplicative,
            )
            if result:
                results.append(result)

    decomposition_suffix = "_multiplicative" if use_multiplicative else ""
    summary_csv_path = f"./data/analysis_summary_multi_freq{decomposition_suffix}.csv"
    summary_df = pd.DataFrame(results)
    summary_df.to_csv(summary_csv_path, index=False)
    print(f"\nğŸ“Š Summary saved to: {summary_csv_path}")
    print(f"ğŸ“ˆ Total valid factors processed: {len(summary_df)}")

    return summary_df


# ========== å¤„ç†æŒ‡å®šå› å­åˆ—è¡¨çš„å‡½æ•° ==========
def process_selected_factors(factor_list, use_multiplicative=False):
    """
    å¤„ç†å¹¶ç»˜å›¾æŒ‡å®šçš„å› å­åˆ—è¡¨

    Parameters:
    factor_list: list of str, è¦å¤„ç†çš„å› å­åç§°åˆ—è¡¨
    use_multiplicative: bool, æ˜¯å¦ä½¿ç”¨ä¹˜æ³•åˆ†è§£

    Returns:
    summary_df: DataFrame, åŒ…å«æ‰€é€‰å› å­çš„ç»Ÿè®¡æŒ‡æ ‡æ±‡æ€»
    """
    results = []
    processed_factors = set()  # ç”¨äºè·Ÿè¸ªå·²å¤„ç†çš„å› å­ï¼Œé¿å…é‡å¤

    for category in os.listdir(DATA_DIR):
        category_path = os.path.join(DATA_DIR, category)
        if not os.path.isdir(category_path):
            continue

        print(f"\nğŸ” Searching in category: {category}")

        for filename in os.listdir(category_path):
            if not filename.endswith(".csv"):
                continue

            match = re.match(r"BTC_(\d+[mh])_(.+)\.csv", filename)
            if not match:
                continue

            freq = match.group(1)
            factor_name = match.group(2)

            if freq not in ["10m", "1h", "24h"]:
                continue

            # æ£€æŸ¥è¿™ä¸ªå› å­æ˜¯å¦åœ¨æˆ‘ä»¬æƒ³è¦å¤„ç†çš„åˆ—è¡¨ä¸­
            if factor_name in factor_list and factor_name not in processed_factors:
                filepath = os.path.join(category_path, filename)
                print(
                    f"ğŸ¯ Processing selected factor: {factor_name} (freq: {freq}) - {['Additive', 'Multiplicative'][use_multiplicative]} decomposition"
                )

                result = process_single_factor(
                    filepath,
                    category,
                    factor_name,
                    freq,
                    use_multiplicative=use_multiplicative,
                )
                if result:
                    results.append(result)
                    processed_factors.add(factor_name)

    # æ£€æŸ¥æ˜¯å¦æœ‰å› å­æ²¡æœ‰æ‰¾åˆ°
    not_found = set(factor_list) - processed_factors
    if not_found:
        print(f"\nâš ï¸ The following factors were not found: {list(not_found)}")

    # ä¿å­˜ç»“æœ
    decomposition_type = "multiplicative" if use_multiplicative else "additive"
    selected_summary_path = f"./data/selected_factors_analysis_{decomposition_type}.csv"
    summary_df = pd.DataFrame(results)
    summary_df.to_csv(selected_summary_path, index=False)
    print(f"\nğŸ“Š Selected factors summary saved to: {selected_summary_path}")
    print(f"ğŸ“ˆ Total selected factors processed: {len(summary_df)}")

    return summary_df


# ========== è¿è¡Œ ==========
if __name__ == "__main__":

    # æ‰¹é‡å¤„ç†æ‰€æœ‰å› å­ï¼ˆåŠ æ³•åˆ†è§£ï¼‰
    print("=== Processing all factors with additive decomposition ===")
    summary_additive = batch_process_factors(use_multiplicative=False)

    # # æ‰¹é‡å¤„ç†æ‰€æœ‰å› å­ï¼ˆä¹˜æ³•åˆ†è§£ï¼‰
    # print("\n=== Processing all factors with multiplicative decomposition ===")
    # summary_multiplicative = batch_process_factors(use_multiplicative=True)

    print("\n=== Processing selected factors ===")
    selected_factors = [
        "active_1m_3m",
        "count",
        "supply_balance_less_0001",
        "liquid_sum",
    ]  # ç¤ºä¾‹å› å­åˆ—è¡¨
    selected_summary = process_selected_factors(
        selected_factors, use_multiplicative=True
    )

    print("\nâœ… All done!")
